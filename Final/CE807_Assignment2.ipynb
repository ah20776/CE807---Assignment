{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CE807_Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMOQ5vhhMl2upCyuBhzJbIl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ah20776/CE807---Assignment/blob/main/Final/CE807_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W-GmZhWg_WY",
        "outputId": "a8b5f5ca-c32f-4561-83ef-de7849962e7f"
      },
      "source": [
        "!pip install pyLDAvis\n",
        "!pip install gensim\n",
        "!pip install spacy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.15)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.20.2)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.2.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.22.2.post1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (54.2.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.7.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.0.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (1.1.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.20.2)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.0.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (54.2.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.20.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (3.10.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD5Km-pQjqim",
        "outputId": "e3b3591e-ed0a-42f8-d763-6f937b4c45a4"
      },
      "source": [
        "# Load news data set\n",
        "# remove meta data headers footers and quotes from news dataset\n",
        "\n",
        "from pprint import pprint\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "dataset = fetch_20newsgroups(shuffle=True,\n",
        "                            random_state=32,\n",
        "                            remove=('headers', 'footers', 'qutes'))\n",
        "\n",
        "#\n",
        "dataset_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=32, remove=('headers', 'footers', 'qutes'))\n",
        "dataset_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=32, remove=('headers', 'footers', 'qutes'))\n",
        "# Check the names of the categories\n",
        "pprint(dataset.target_names)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['alt.atheism',\n",
            " 'comp.graphics',\n",
            " 'comp.os.ms-windows.misc',\n",
            " 'comp.sys.ibm.pc.hardware',\n",
            " 'comp.sys.mac.hardware',\n",
            " 'comp.windows.x',\n",
            " 'misc.forsale',\n",
            " 'rec.autos',\n",
            " 'rec.motorcycles',\n",
            " 'rec.sport.baseball',\n",
            " 'rec.sport.hockey',\n",
            " 'sci.crypt',\n",
            " 'sci.electronics',\n",
            " 'sci.med',\n",
            " 'sci.space',\n",
            " 'soc.religion.christian',\n",
            " 'talk.politics.guns',\n",
            " 'talk.politics.mideast',\n",
            " 'talk.politics.misc',\n",
            " 'talk.religion.misc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDVccnlbk9w_",
        "outputId": "adf6658d-8467-42d1-d5ae-42fa1eb2f4b5"
      },
      "source": [
        "\n",
        "'''\n",
        "Loading Gensim and nltk libraries\n",
        "'''\n",
        "# pip install gensim\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "import gensim.corpora as corpora\n",
        "from gensim.models import CoherenceModel\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(400)\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "import pandas as pd\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import spacy\n",
        "from spacy.lang.en.examples import sentences"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL7e9skkn3tu"
      },
      "source": [
        "'''\n",
        "Write a function to perform the pre processing steps on the entire dataset\n",
        "'''\n",
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "# Tokenize and lemmatize\n",
        "def preprocess(text):\n",
        "    result=[]\n",
        "    for token in gensim.utils.simple_preprocess(text) :\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "            \n",
        "    return result"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyQboPY9n7Di",
        "outputId": "6f219927-725b-4146-9124-e6cb4edde389"
      },
      "source": [
        "processed_docs = []\n",
        "\n",
        "for doc in dataset_train.data:\n",
        "    processed_docs.append(preprocess(doc))\n",
        "\n",
        "'''\n",
        "Preview 'processed_docs'\n",
        "'''\n",
        "pprint(processed_docs[:2])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['real',\n",
            "  'question',\n",
            "  'opinion',\n",
            "  'motorola',\n",
            "  'processor',\n",
            "  'run',\n",
            "  'compar',\n",
            "  'intel',\n",
            "  'processor',\n",
            "  'run',\n",
            "  'window',\n",
            "  'recal',\n",
            "  'convers',\n",
            "  'run',\n",
            "  'window',\n",
            "  'benchmark',\n",
            "  'speed',\n",
            "  'know',\n",
            "  'true',\n",
            "  'love',\n",
            "  'hear',\n",
            "  'technic',\n",
            "  'data',\n",
            "  'david'],\n",
            " ['current',\n",
            "  'street',\n",
            "  'price',\n",
            "  'follow',\n",
            "  'relev',\n",
            "  'tax',\n",
            "  'simm',\n",
            "  'simm',\n",
            "  'refund',\n",
            "  'possibl',\n",
            "  'export',\n",
            "  'recommend',\n",
            "  'reliabl',\n",
            "  'supplier']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L7bCZWSoY2s",
        "outputId": "e5a76810-18c5-49db-ba9c-e83deb6f335a"
      },
      "source": [
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
        "bigram = gensim.models.Phrases(processed_docs, min_count=5, threshold=100)\n",
        "trigram = gensim.models.Phrases(bigram[processed_docs], threshold=100)\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "def remove_stopwords(texts):\n",
        "   return [[word for word in simple_preprocess(str(doc)) \n",
        "   if word not in stop_words] for doc in texts]\n",
        "def make_bigrams(texts):\n",
        "   return [bigram_mod[doc] for doc in texts]\n",
        "def make_trigrams(texts):\n",
        "   [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "   texts_out = []\n",
        "   for sent in texts:\n",
        "      doc = nlp(\" \".join(sent))\n",
        "      texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "   return texts_out\n",
        "data_words_nostops = remove_stopwords(processed_docs)\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=[\n",
        "   'NOUN', 'ADJ', 'VERB', 'ADV'\n",
        "])\n",
        "print(data_lemmatized[:4]) #it will print the lemmatized data."
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[['real', 'question', 'opinion', 'window', 'recal', 'conver', 'run', 'window', 'benchmark', 'speed', 'know', 'true', 'love', 'hear', 'technic'], ['current', 'street', 'price', 'follow', 'refund', 'reliabl', 'supplier'], ['help', 'inform', 'card', 'reader', 'recent', 'buy', 'local', 'surplus', 'dealer', 'rear', 'follow', 'inform', 'card', 'reader', 'connector', 'power', 'connector'], ['write', 'sick', 'call', 'legisl', 'unseal', 'involv', 'atroc', 'includ', 'presid', 'attorney_general', 'governor', 'suspend', 'pend', 'serious', 'doubt']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6rL6gBqyMcI",
        "outputId": "b2160151-23aa-4951-d156-d80f4b5e26f3"
      },
      "source": [
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "texts = data_lemmatized\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "print(corpus[:4]) #it will print the corpus we created above.\n",
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:4]] \n",
        "#it will print the words with their frequencies.\n",
        "lda_model = gensim.models.ldamodel.LdaModel(\n",
        "   corpus=corpus, id2word=id2word, num_topics=10, random_state=100, \n",
        "   update_every=1, chunksize=100, passes=10, alpha='auto', per_word_topics=True\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 2)], [(14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1)], [(15, 1), (21, 1), (22, 2), (23, 2), (24, 1), (25, 1), (26, 2), (27, 1), (28, 1), (29, 2), (30, 1), (31, 1), (32, 1)], [(33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp_h7il13iko",
        "outputId": "00f9bdfa-0e62-489b-fd0f-a10515ac9bdc"
      },
      "source": [
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.076*\"right\" + 0.030*\"discuss\" + 0.030*\"case\" + 0.026*\"probabl\" + '\n",
            "  '0.025*\"public\" + 0.023*\"group\" + 0.022*\"stop\" + 0.022*\"author\" + '\n",
            "  '0.020*\"clear\" + 0.019*\"hold\"'),\n",
            " (1,\n",
            "  '0.040*\"obvious\" + 0.037*\"opinion\" + 0.035*\"grind\" + 0.031*\"agre\" + '\n",
            "  '0.028*\"plan\" + 0.026*\"rememb\" + 0.023*\"land\" + 0.023*\"decid\" + 0.022*\"mile\" '\n",
            "  '+ 0.020*\"metal\"'),\n",
            " (2,\n",
            "  '0.083*\"look\" + 0.065*\"help\" + 0.062*\"good\" + 0.039*\"send\" + 0.039*\"post\" + '\n",
            "  '0.029*\"order\" + 0.027*\"month\" + 0.026*\"sell\" + 0.020*\"guess\" + '\n",
            "  '0.019*\"model\"'),\n",
            " (3,\n",
            "  '0.041*\"problem\" + 0.035*\"drive\" + 0.033*\"work\" + 0.031*\"high\" + '\n",
            "  '0.025*\"card\" + 0.024*\"support\" + 0.022*\"need\" + 0.020*\"control\" + '\n",
            "  '0.017*\"driver\" + 0.016*\"type\"'),\n",
            " (4,\n",
            "  '0.033*\"exist\" + 0.032*\"argument\" + 0.029*\"claim\" + 0.028*\"true\" + '\n",
            "  '0.023*\"accept\" + 0.020*\"believ\" + 0.019*\"wrong\" + 0.016*\"religion\" + '\n",
            "  '0.016*\"truth\" + 0.015*\"reason\"'),\n",
            " (5,\n",
            "  '0.043*\"list\" + 0.039*\"mail\" + 0.034*\"line\" + 0.031*\"inform\" + 0.025*\"space\" '\n",
            "  '+ 0.024*\"includ\" + 0.023*\"univer\" + 0.022*\"stuff\" + 0.021*\"unit\" + '\n",
            "  '0.021*\"offer\"'),\n",
            " (6,\n",
            "  '0.020*\"research\" + 0.018*\"effect\" + 0.017*\"doctor\" + 0.017*\"treatment\" + '\n",
            "  '0.017*\"orbit\" + 0.016*\"boss\" + 0.015*\"high\" + 0.014*\"develop\" + '\n",
            "  '0.014*\"drug\" + 0.013*\"disea\"'),\n",
            " (7,\n",
            "  '0.049*\"color\" + 0.037*\"process\" + 0.035*\"option\" + 0.034*\"develop\" + '\n",
            "  '0.033*\"function\" + 0.032*\"product\" + 0.027*\"user\" + 0.022*\"applic\" + '\n",
            "  '0.021*\"avail\" + 0.018*\"tool\"'),\n",
            " (8,\n",
            "  '0.114*\"object\" + 0.060*\"moral\" + 0.032*\"finger\" + 0.027*\"extrem\" + '\n",
            "  '0.026*\"harm\" + 0.026*\"bother\" + 0.022*\"stream\" + 0.017*\"satellit\" + '\n",
            "  '0.015*\"photographi\" + 0.015*\"motif\"'),\n",
            " (9,\n",
            "  '0.115*\"wire\" + 0.044*\"monitor\" + 0.032*\"video\" + 0.028*\"info\" + '\n",
            "  '0.026*\"appl\" + 0.024*\"mous\" + 0.023*\"server\" + 0.020*\"outlet\" + '\n",
            "  '0.018*\"store\" + 0.017*\"shop\"'),\n",
            " (10,\n",
            "  '0.041*\"later\" + 0.039*\"bring\" + 0.038*\"pain\" + 0.029*\"suffer\" + '\n",
            "  '0.026*\"save\" + 0.025*\"throw\" + 0.024*\"shall\" + 0.023*\"food\" + 0.018*\"slot\" '\n",
            "  '+ 0.018*\"bit\"'),\n",
            " (11,\n",
            "  '0.030*\"peopl\" + 0.029*\"govern\" + 0.021*\"kill\" + 0.019*\"child\" + '\n",
            "  '0.016*\"woman\" + 0.015*\"live\" + 0.013*\"dead\" + 0.013*\"attack\" + '\n",
            "  '0.012*\"state\" + 0.011*\"armenian\"'),\n",
            " (12,\n",
            "  '0.043*\"nation\" + 0.043*\"hous\" + 0.025*\"member\" + 0.020*\"presid\" + '\n",
            "  '0.020*\"press\" + 0.019*\"present\" + 0.017*\"american\" + 0.016*\"canadian\" + '\n",
            "  '0.015*\"station\" + 0.014*\"polit\"'),\n",
            " (13,\n",
            "  '0.040*\"input\" + 0.036*\"brake\" + 0.034*\"frequenc\" + 0.030*\"radio\" + '\n",
            "  '0.026*\"traffic\" + 0.025*\"circuit\" + 0.024*\"heal\" + 0.023*\"probe\" + '\n",
            "  '0.020*\"output\" + 0.020*\"construct\"'),\n",
            " (14,\n",
            "  '0.040*\"protect\" + 0.033*\"bike\" + 0.030*\"legal\" + 0.030*\"safe\" + '\n",
            "  '0.026*\"owner\" + 0.024*\"instead\" + 0.023*\"boot\" + 0.018*\"road\" + '\n",
            "  '0.018*\"foot\" + 0.016*\"class\"'),\n",
            " (15,\n",
            "  '0.100*\"file\" + 0.087*\"program\" + 0.083*\"window\" + 0.040*\"run\" + '\n",
            "  '0.034*\"instal\" + 0.028*\"display\" + 0.018*\"screen\" + 0.017*\"extra\" + '\n",
            "  '0.016*\"open\" + 0.016*\"string\"'),\n",
            " (16,\n",
            "  '0.045*\"write\" + 0.041*\"know\" + 0.033*\"think\" + 0.025*\"time\" + 0.025*\"say\" + '\n",
            "  '0.021*\"go\" + 0.021*\"come\" + 0.017*\"want\" + 0.017*\"thing\" + '\n",
            "  '0.015*\"question\"'),\n",
            " (17,\n",
            "  '0.044*\"return\" + 0.043*\"disk\" + 0.043*\"player\" + 0.028*\"point\" + '\n",
            "  '0.024*\"form\" + 0.024*\"launch\" + 0.020*\"watch\" + 0.019*\"assum\" + '\n",
            "  '0.019*\"ship\" + 0.017*\"deserv\"'),\n",
            " (18,\n",
            "  '0.044*\"entri\" + 0.036*\"defen\" + 0.030*\"solid\" + 0.027*\"shape\" + '\n",
            "  '0.027*\"stat\" + 0.026*\"consider\" + 0.024*\"structur\" + 0.024*\"plastic\" + '\n",
            "  '0.023*\"spot\" + 0.021*\"trade\"'),\n",
            " (19,\n",
            "  '0.077*\"game\" + 0.044*\"team\" + 0.044*\"play\" + 0.035*\"year\" + 0.033*\"deal\" + '\n",
            "  '0.029*\"lose\" + 0.024*\"season\" + 0.018*\"myer\" + 0.017*\"good\" + '\n",
            "  '0.017*\"score\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRNDSVUw3mwT",
        "outputId": "c296a965-5d56-4f8c-9422-d0bb96a9115d"
      },
      "source": [
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Perplexity:  -7.934359046077182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TB55cRT3vxh",
        "outputId": "31d1ca11-8d30-44c3-ace9-e98ea75e072d"
      },
      "source": [
        "coherence_model_lda = CoherenceModel(\n",
        "   model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v'\n",
        ")\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Coherence Score:  0.3884752068244352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzR_gUFc5acn"
      },
      "source": [
        "# supporting function\n",
        "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
        "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=k, random_state=100, \n",
        "    update_every=1, chunksize=100, passes=10, alpha=a, eta=b, per_word_topics=True)\n",
        "\n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "    \n",
        "    return coherence_model_lda.get_coherence()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XMUd42gq5b07",
        "outputId": "d7cb4df7-04ec-440d-8566-7f4d578c7495"
      },
      "source": [
        "import numpy as np\n",
        "import tqdm\n",
        "from google.colab import files\n",
        "\n",
        "grid = {}\n",
        "grid['Validation_Set'] = {}\n",
        "\n",
        "# Topics range\n",
        "min_topics = 0\n",
        "max_topics = 30\n",
        "step_size = 2\n",
        "topics_range = range(min_topics, max_topics, step_size)\n",
        "\n",
        "# Alpha parameter\n",
        "alpha = list(np.arange(0.01, 1, 0.3))\n",
        "alpha.append('symmetric')\n",
        "alpha.append('asymmetric')\n",
        "\n",
        "# Beta parameter\n",
        "beta = list(np.arange(0.01, 1, 0.3))\n",
        "beta.append('symmetric')\n",
        "\n",
        "# Validation sets\n",
        "num_of_docs = len(corpus)\n",
        "corpus_sets = [gensim.utils.ClippedCorpus(corpus, int(num_of_docs*0.75)), \n",
        "               corpus]\n",
        "\n",
        "corpus_title = ['75% Corpus', '100% Corpus']\n",
        "\n",
        "model_results = {'Validation_Set': [],\n",
        "                 'Topics': [],\n",
        "                 'Alpha': [],\n",
        "                 'Beta': [],\n",
        "                 'Coherence': []\n",
        "                }\n",
        "\n",
        "# Can take a long time to run\n",
        "if 1 == 1:\n",
        "    pbar = tqdm.tqdm(total=(len(beta)*len(alpha)*len(topics_range)*len(corpus_title)))\n",
        "    \n",
        "    # iterate through validation corpuses\n",
        "    for i in range(len(corpus_sets)):\n",
        "        # iterate through number of topics\n",
        "        for k in topics_range:\n",
        "            # iterate through alpha values\n",
        "            for a in alpha:\n",
        "                # iterare through beta values\n",
        "                for b in beta:\n",
        "                    # get the coherence score for the given parameters\n",
        "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
        "                                                  k=k, a=a, b=b)\n",
        "                    # Save the model results\n",
        "                    model_results['Validation_Set'].append(corpus_title[i])\n",
        "                    model_results['Topics'].append(k)\n",
        "                    model_results['Alpha'].append(a)\n",
        "                    model_results['Beta'].append(b)\n",
        "                    model_results['Coherence'].append(cv)\n",
        "                    \n",
        "                    pbar.update(1)\n",
        "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
        "    files.download('lda_tuning_results.csv')\n",
        "    pbar.close()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/300 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  0%|          | 0/300 [00:06<?, ?it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
            "  diff = np.log(self.expElogbeta)\n",
            "\n",
            "\n",
            "  0%|          | 1/300 [00:53<4:24:19, 53.04s/it]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 2/300 [01:49<4:29:15, 54.21s/it]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 3/300 [02:50<4:37:42, 56.10s/it]\u001b[A\u001b[A\n",
            "\n",
            "  1%|▏         | 4/300 [03:44<4:33:07, 55.36s/it]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 5/300 [04:36<4:28:10, 54.54s/it]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 6/300 [05:34<4:31:18, 55.37s/it]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 7/300 [06:34<4:37:45, 56.88s/it]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 8/300 [07:37<4:46:28, 58.86s/it]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 9/300 [08:42<4:53:40, 60.55s/it]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 10/300 [09:39<4:48:10, 59.62s/it]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▎         | 11/300 [10:33<4:38:45, 57.87s/it]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 12/300 [11:30<4:35:36, 57.42s/it]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 13/300 [12:29<4:37:25, 58.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▍         | 14/300 [13:27<4:36:54, 58.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▌         | 15/300 [14:21<4:30:15, 56.90s/it]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▌         | 16/300 [15:10<4:17:35, 54.42s/it]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 17/300 [16:02<4:13:38, 53.78s/it]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 18/300 [16:55<4:11:17, 53.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▋         | 19/300 [17:47<4:08:08, 52.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 20/300 [18:38<4:04:02, 52.29s/it]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 21/300 [19:32<4:06:53, 53.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 22/300 [20:30<4:12:10, 54.43s/it]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 23/300 [21:32<4:21:28, 56.64s/it]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 24/300 [22:33<4:26:15, 57.88s/it]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 25/300 [23:26<4:19:32, 56.63s/it]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▊         | 26/300 [24:20<4:15:09, 55.88s/it]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 27/300 [25:19<4:17:30, 56.60s/it]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 28/300 [26:18<4:20:48, 57.53s/it]\u001b[A\u001b[A\n",
            "\n",
            " 10%|▉         | 29/300 [27:20<4:25:51, 58.86s/it]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 30/300 [28:14<4:18:19, 57.41s/it]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 31/300 [29:20<4:28:43, 59.94s/it]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 32/300 [30:24<4:32:42, 61.05s/it]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 33/300 [31:26<4:33:19, 61.42s/it]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█▏        | 34/300 [32:28<4:33:10, 61.62s/it]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 35/300 [33:32<4:34:55, 62.25s/it]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 36/300 [34:44<4:46:27, 65.11s/it]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 37/300 [35:54<4:52:25, 66.71s/it]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 38/300 [37:02<4:52:28, 66.98s/it]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 39/300 [38:09<4:51:30, 67.02s/it]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 40/300 [39:20<4:55:50, 68.27s/it]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▎        | 41/300 [40:25<4:50:14, 67.24s/it]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 42/300 [41:32<4:48:20, 67.05s/it]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 43/300 [42:39<4:47:42, 67.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▍        | 44/300 [43:41<4:40:10, 65.67s/it]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 45/300 [44:48<4:40:03, 65.90s/it]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 46/300 [45:49<4:33:39, 64.65s/it]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 47/300 [46:54<4:32:11, 64.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 48/300 [47:57<4:30:00, 64.29s/it]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▋        | 49/300 [48:58<4:24:32, 63.24s/it]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 50/300 [50:01<4:23:27, 63.23s/it]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 51/300 [51:09<4:27:53, 64.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 52/300 [52:13<4:26:21, 64.44s/it]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 53/300 [53:16<4:23:12, 63.94s/it]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 54/300 [54:19<4:21:37, 63.81s/it]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 55/300 [55:24<4:21:36, 64.07s/it]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▊        | 56/300 [56:32<4:25:21, 65.25s/it]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 57/300 [57:36<4:23:07, 64.97s/it]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 58/300 [58:41<4:21:07, 64.74s/it]\u001b[A\u001b[A\n",
            "\n",
            " 20%|█▉        | 59/300 [59:46<4:20:13, 64.79s/it]\u001b[A\u001b[A\n",
            "\n",
            " 20%|██        | 60/300 [1:00:52<4:21:24, 65.35s/it]\u001b[A\u001b[A\n",
            "\n",
            " 20%|██        | 61/300 [1:02:18<4:45:09, 71.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 62/300 [1:03:39<4:54:42, 74.30s/it]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 63/300 [1:04:55<4:55:59, 74.93s/it]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██▏       | 64/300 [1:06:12<4:56:48, 75.46s/it]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 65/300 [1:07:40<5:09:46, 79.09s/it]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 66/300 [1:09:13<5:25:08, 83.37s/it]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 67/300 [1:10:40<5:27:58, 84.46s/it]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 68/300 [1:12:02<5:24:18, 83.87s/it]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 69/300 [1:13:23<5:18:55, 82.84s/it]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 70/300 [1:14:56<5:29:13, 85.89s/it]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▎       | 71/300 [1:16:21<5:27:16, 85.75s/it]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 72/300 [1:17:45<5:23:41, 85.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 73/300 [1:19:06<5:17:33, 83.94s/it]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▍       | 74/300 [1:20:21<5:05:59, 81.24s/it]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 75/300 [1:21:47<5:09:30, 82.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 76/300 [1:23:11<5:10:04, 83.05s/it]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 77/300 [1:24:33<5:08:01, 82.88s/it]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 78/300 [1:25:48<4:57:50, 80.50s/it]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▋       | 79/300 [1:27:05<4:52:26, 79.40s/it]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 80/300 [1:28:27<4:54:06, 80.21s/it]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 81/300 [1:29:54<5:00:20, 82.29s/it]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 82/300 [1:31:14<4:55:41, 81.38s/it]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 83/300 [1:32:30<4:49:06, 79.94s/it]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 84/300 [1:33:46<4:42:45, 78.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 85/300 [1:35:10<4:48:09, 80.42s/it]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▊       | 86/300 [1:36:37<4:53:53, 82.40s/it]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 87/300 [1:37:57<4:49:28, 81.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 88/300 [1:39:14<4:43:11, 80.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 30%|██▉       | 89/300 [1:40:31<4:38:55, 79.31s/it]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 90/300 [1:41:55<4:42:07, 80.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 91/300 [1:43:41<5:07:56, 88.40s/it]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 92/300 [1:45:14<5:11:16, 89.79s/it]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 93/300 [1:46:47<5:12:11, 90.49s/it]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███▏      | 94/300 [1:48:18<5:11:45, 90.80s/it]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 95/300 [1:50:01<5:23:08, 94.58s/it]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 96/300 [1:51:54<5:39:39, 99.90s/it]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 97/300 [1:53:35<5:39:38, 100.39s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 98/300 [1:55:09<5:31:17, 98.41s/it] \u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 99/300 [1:56:46<5:27:52, 97.87s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 100/300 [1:58:37<5:39:18, 101.79s/it]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▎      | 101/300 [2:00:24<5:43:11, 103.47s/it]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 102/300 [2:02:04<5:37:33, 102.29s/it]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 103/300 [2:03:34<5:24:36, 98.87s/it] \u001b[A\u001b[A\n",
            "\n",
            " 35%|███▍      | 104/300 [2:05:03<5:12:53, 95.78s/it]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▌      | 105/300 [2:06:53<5:25:16, 100.08s/it]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▌      | 106/300 [2:08:43<5:32:39, 102.88s/it]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 107/300 [2:10:21<5:26:54, 101.63s/it]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 108/300 [2:11:52<5:14:52, 98.40s/it] \u001b[A\u001b[A\n",
            "\n",
            " 36%|███▋      | 109/300 [2:13:19<5:02:26, 95.01s/it]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 110/300 [2:15:02<5:08:26, 97.40s/it]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 111/300 [2:16:50<5:16:58, 100.63s/it]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 112/300 [2:18:24<5:08:52, 98.58s/it] \u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 113/300 [2:19:56<5:01:10, 96.63s/it]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 114/300 [2:21:30<4:57:16, 95.90s/it]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 115/300 [2:23:15<5:03:39, 98.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▊      | 116/300 [2:25:00<5:08:24, 100.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 117/300 [2:26:36<5:01:52, 98.98s/it] \u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 118/300 [2:28:09<4:54:37, 97.13s/it]\u001b[A\u001b[A\n",
            "\n",
            " 40%|███▉      | 119/300 [2:29:42<4:49:55, 96.11s/it]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 120/300 [2:31:27<4:56:07, 98.71s/it]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 121/300 [2:33:34<5:19:56, 107.24s/it]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 122/300 [2:35:24<5:20:37, 108.08s/it]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 123/300 [2:37:11<5:17:33, 107.65s/it]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████▏     | 124/300 [2:38:58<5:14:56, 107.37s/it]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 125/300 [2:41:00<5:26:42, 112.02s/it]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 126/300 [2:43:17<5:46:18, 119.42s/it]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 127/300 [2:45:11<5:39:47, 117.85s/it]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 128/300 [2:47:02<5:31:59, 115.81s/it]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 129/300 [2:48:51<5:24:11, 113.75s/it]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 130/300 [2:51:06<5:39:57, 119.99s/it]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▎     | 131/300 [2:53:16<5:46:41, 123.08s/it]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 132/300 [2:55:14<5:39:50, 121.37s/it]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 133/300 [2:57:03<5:27:34, 117.69s/it]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▍     | 134/300 [2:58:51<5:17:51, 114.89s/it]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▌     | 135/300 [3:01:03<5:30:24, 120.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▌     | 136/300 [3:03:14<5:37:14, 123.38s/it]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 137/300 [3:05:10<5:29:16, 121.21s/it]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 138/300 [3:06:55<5:13:49, 116.23s/it]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▋     | 139/300 [3:08:37<5:00:36, 112.03s/it]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 140/300 [3:10:45<5:11:28, 116.80s/it]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 141/300 [3:12:54<5:18:58, 120.37s/it]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 142/300 [3:14:42<5:07:22, 116.73s/it]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 143/300 [3:16:28<4:56:55, 113.47s/it]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 144/300 [3:18:14<4:49:32, 111.36s/it]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 145/300 [3:20:18<4:57:02, 114.98s/it]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▊     | 146/300 [3:22:26<5:04:58, 118.82s/it]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 147/300 [3:24:16<4:56:19, 116.21s/it]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 148/300 [3:26:03<4:47:37, 113.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|████▉     | 149/300 [3:27:51<4:41:14, 111.75s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 150/300 [3:29:57<4:49:59, 116.00s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 151/300 [3:31:06<4:13:19, 102.01s/it]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 152/300 [3:32:21<3:52:00, 94.06s/it] \u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 153/300 [3:33:41<3:39:47, 89.71s/it]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████▏    | 154/300 [3:35:02<3:31:43, 87.01s/it]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 155/300 [3:36:11<3:17:28, 81.71s/it]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 156/300 [3:37:27<3:11:41, 79.87s/it]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 157/300 [3:38:47<3:10:41, 80.01s/it]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 158/300 [3:40:11<3:12:02, 81.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 159/300 [3:41:35<3:13:11, 82.21s/it]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 160/300 [3:42:51<3:06:53, 80.10s/it]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▎    | 161/300 [3:43:59<2:57:34, 76.65s/it]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 162/300 [3:45:13<2:54:16, 75.77s/it]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 163/300 [3:46:30<2:53:54, 76.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▍    | 164/300 [3:47:49<2:54:40, 77.06s/it]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▌    | 165/300 [3:48:59<2:48:26, 74.87s/it]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▌    | 166/300 [3:50:02<2:39:21, 71.36s/it]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 167/300 [3:51:10<2:36:04, 70.41s/it]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 168/300 [3:52:21<2:34:48, 70.37s/it]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▋    | 169/300 [3:53:30<2:33:02, 70.10s/it]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 170/300 [3:54:36<2:29:09, 68.84s/it]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 171/300 [3:55:47<2:29:42, 69.63s/it]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 172/300 [3:57:03<2:32:39, 71.56s/it]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 173/300 [3:58:24<2:37:20, 74.33s/it]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 174/300 [3:59:46<2:41:00, 76.67s/it]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 175/300 [4:00:57<2:35:55, 74.84s/it]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▊    | 176/300 [4:02:09<2:32:50, 73.96s/it]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 177/300 [4:03:27<2:33:56, 75.09s/it]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 178/300 [4:04:47<2:36:00, 76.72s/it]\u001b[A\u001b[A\n",
            "\n",
            " 60%|█████▉    | 179/300 [4:06:07<2:36:41, 77.70s/it]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 180/300 [4:07:18<2:31:35, 75.79s/it]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 181/300 [4:08:45<2:36:43, 79.02s/it]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 182/300 [4:10:11<2:39:37, 81.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 183/300 [4:11:37<2:40:56, 82.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████▏   | 184/300 [4:13:00<2:40:09, 82.84s/it]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 185/300 [4:14:25<2:39:32, 83.24s/it]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 186/300 [4:15:58<2:44:02, 86.34s/it]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 187/300 [4:17:35<2:48:15, 89.34s/it]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 188/300 [4:19:09<2:49:23, 90.75s/it]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 189/300 [4:20:39<2:47:56, 90.78s/it]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 190/300 [4:22:13<2:47:56, 91.60s/it]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▎   | 191/300 [4:23:37<2:42:05, 89.23s/it]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 192/300 [4:25:05<2:40:21, 89.09s/it]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 193/300 [4:26:35<2:39:05, 89.21s/it]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▍   | 194/300 [4:28:02<2:36:26, 88.56s/it]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▌   | 195/300 [4:29:28<2:33:45, 87.87s/it]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▌   | 196/300 [4:30:48<2:27:53, 85.32s/it]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 197/300 [4:32:12<2:26:00, 85.05s/it]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 198/300 [4:33:37<2:24:47, 85.17s/it]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▋   | 199/300 [4:35:01<2:22:35, 84.71s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 200/300 [4:36:22<2:19:11, 83.52s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 201/300 [4:37:49<2:19:33, 84.58s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 202/300 [4:39:14<2:18:34, 84.84s/it]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 203/300 [4:40:40<2:17:36, 85.12s/it]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 204/300 [4:42:03<2:15:07, 84.45s/it]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 205/300 [4:43:28<2:13:52, 84.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▊   | 206/300 [4:44:56<2:14:12, 85.66s/it]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 207/300 [4:46:24<2:13:52, 86.37s/it]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 208/300 [4:47:51<2:12:43, 86.56s/it]\u001b[A\u001b[A\n",
            "\n",
            " 70%|██████▉   | 209/300 [4:49:19<2:11:42, 86.84s/it]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 210/300 [4:50:46<2:10:35, 87.06s/it]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 211/300 [4:52:39<2:20:27, 94.69s/it]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 212/300 [4:54:32<2:27:03, 100.27s/it]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 213/300 [4:56:16<2:26:58, 101.37s/it]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████▏  | 214/300 [4:57:57<2:25:08, 101.27s/it]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 215/300 [4:59:47<2:27:04, 103.82s/it]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 216/300 [5:01:44<2:30:57, 107.83s/it]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 217/300 [5:03:40<2:32:47, 110.46s/it]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 218/300 [5:05:29<2:30:15, 109.94s/it]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 219/300 [5:07:13<2:26:08, 108.26s/it]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 220/300 [5:09:12<2:28:16, 111.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▎  | 221/300 [5:11:01<2:25:31, 110.53s/it]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 222/300 [5:12:50<2:23:15, 110.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 223/300 [5:14:38<2:20:29, 109.47s/it]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▍  | 224/300 [5:16:20<2:15:46, 107.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 225/300 [5:18:07<2:14:11, 107.36s/it]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 226/300 [5:19:53<2:11:39, 106.76s/it]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 227/300 [5:21:39<2:09:41, 106.60s/it]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 228/300 [5:23:21<2:06:07, 105.11s/it]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▋  | 229/300 [5:24:59<2:02:09, 103.23s/it]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 230/300 [5:26:45<2:01:13, 103.90s/it]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 231/300 [5:28:37<2:02:29, 106.51s/it]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 232/300 [5:30:25<2:01:11, 106.93s/it]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 233/300 [5:32:09<1:58:27, 106.08s/it]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 234/300 [5:33:51<1:55:11, 104.72s/it]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 235/300 [5:35:41<1:55:12, 106.34s/it]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▊  | 236/300 [5:37:33<1:55:13, 108.02s/it]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 237/300 [5:39:18<1:52:26, 107.09s/it]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 238/300 [5:41:03<1:50:01, 106.47s/it]\u001b[A\u001b[A\n",
            "\n",
            " 80%|███████▉  | 239/300 [5:42:49<1:48:04, 106.30s/it]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 240/300 [5:44:36<1:46:32, 106.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 241/300 [5:46:53<1:53:42, 115.63s/it]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 242/300 [5:48:59<1:54:43, 118.68s/it]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 243/300 [5:51:03<1:54:14, 120.26s/it]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████▏ | 244/300 [5:53:06<1:53:12, 121.30s/it]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 245/300 [5:55:19<1:54:14, 124.63s/it]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 246/300 [5:57:43<1:57:29, 130.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 247/300 [6:00:04<1:57:57, 133.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 248/300 [6:02:12<1:54:30, 132.13s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 249/300 [6:04:17<1:50:24, 129.89s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 250/300 [6:06:40<1:51:23, 133.66s/it]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▎ | 251/300 [6:08:54<1:49:19, 133.86s/it]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 252/300 [6:11:07<1:46:50, 133.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 253/300 [6:13:11<1:42:25, 130.74s/it]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▍ | 254/300 [6:15:09<1:37:26, 127.10s/it]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▌ | 255/300 [6:17:24<1:37:00, 129.35s/it]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▌ | 256/300 [6:19:35<1:35:12, 129.83s/it]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 257/300 [6:21:45<1:32:58, 129.73s/it]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 258/300 [6:23:45<1:28:46, 126.82s/it]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▋ | 259/300 [6:25:44<1:25:02, 124.45s/it]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 260/300 [6:27:53<1:24:01, 126.04s/it]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 261/300 [6:30:11<1:24:07, 129.44s/it]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 262/300 [6:32:16<1:21:13, 128.24s/it]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 263/300 [6:34:20<1:18:12, 126.81s/it]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 264/300 [6:36:21<1:15:05, 125.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 265/300 [6:38:37<1:14:53, 128.38s/it]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▊ | 266/300 [6:40:51<1:13:48, 130.25s/it]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 267/300 [6:43:00<1:11:18, 129.66s/it]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 268/300 [6:45:04<1:08:20, 128.13s/it]\u001b[A\u001b[A\n",
            "\n",
            " 90%|████████▉ | 269/300 [6:47:08<1:05:28, 126.71s/it]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 270/300 [6:49:20<1:04:13, 128.47s/it]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 271/300 [6:52:01<1:06:46, 138.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 272/300 [6:54:27<1:05:34, 140.52s/it]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 273/300 [6:56:46<1:03:01, 140.05s/it]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████▏| 274/300 [6:59:06<1:00:39, 139.99s/it]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 275/300 [7:01:42<1:00:20, 144.82s/it]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 276/300 [7:04:31<1:00:48, 152.01s/it]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 277/300 [7:07:03<58:15, 151.99s/it]  \u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 278/300 [7:09:28<55:02, 150.10s/it]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 279/300 [7:11:55<52:08, 148.95s/it]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 280/300 [7:14:41<51:21, 154.08s/it]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▎| 281/300 [7:17:21<49:24, 156.03s/it]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 282/300 [7:19:55<46:38, 155.47s/it]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 283/300 [7:22:16<42:48, 151.07s/it]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▍| 284/300 [7:24:39<39:37, 148.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▌| 285/300 [7:27:20<38:06, 152.41s/it]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▌| 286/300 [7:29:58<35:54, 153.92s/it]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 287/300 [7:32:31<33:19, 153.80s/it]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 288/300 [7:34:49<29:46, 148.86s/it]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▋| 289/300 [7:37:05<26:36, 145.11s/it]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 290/300 [7:39:41<24:45, 148.53s/it]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 291/300 [7:42:21<22:46, 151.87s/it]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 292/300 [7:44:45<19:54, 149.33s/it]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 293/300 [7:47:06<17:08, 146.92s/it]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 294/300 [7:49:25<14:27, 144.65s/it]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 295/300 [7:52:01<12:19, 147.96s/it]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▊| 296/300 [7:54:42<10:07, 151.77s/it]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 297/300 [7:57:09<07:31, 150.58s/it]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 298/300 [7:59:35<04:58, 149.07s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|█████████▉| 299/300 [8:01:55<02:26, 146.34s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 300/300 [8:04:34<00:00, 150.08s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6cacec8a-f260-4d15-a45c-12653df55a30\", \"lda_tuning_results.csv\", 15491)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 300/300 [8:04:34<00:00, 96.91s/it] \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "JohGxHcGxeJo",
        "outputId": "5b96bf13-f038-46ae-e633-7b65ab08d407"
      },
      "source": [
        "print('Number of unique tokens: %d' % len(id2word)) #dictionary\n",
        "print('Number of documents: %d' % len(corpus))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c9545ee1095e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of unique tokens: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of documents: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'id2word' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgamQ3CBjhad"
      },
      "source": [
        "from pyLDAvis import gensim_models as gensimvis\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "vis_data = gensimvis.prepare(lda_model, corpus, id2word)\n",
        "pyLDAvis.display(vis_data)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}